"""Example environment server generated by `orwd init`."""
from pydantic import BaseModel

from openreward.environments import Environment, JSONObject, Server, TextBlock, ToolOutput, tool


class BasicTaskSpec(BaseModel):
    """
    Each environment has a list of tasks. A task is a dict which contains information about a particular problem in an environment.

    Examples:
    - A math environment might have a problem and a solution
    """
    id: str
    problem: str
    solution: str

class AnswerParams(BaseModel):
    """
    Each tool takes in arguments, and these are specified using types.

    Examples:
    - An answer tool might have an answer argument
    - A bash tool might have a command argument 
    """
    answer: str

# Tasks in an environment can be represented as lists of dictionaries (for each task)
#Â We can also have different splits, e.g. "train" and "test"

train_tasks = [{"id": "train-0", "problem": "What is 2+2?", "solution": "4"}]
test_tasks = [{"id": "test-0", "problem": "What is 2*4?", "solution": "8"}]

class BasicEnvironment(Environment):
    """
    A BasicEnvironment showing the main methods needed to define a working environment.
    """
    def __init__(self, task_spec: JSONObject = {}, secrets: dict[str, str] = {}):
        super().__init__(task_spec)
        self.config = BasicTaskSpec.model_validate(task_spec)

    @classmethod
    def list_tasks(cls, split: str) -> list[JSONObject]:
        """
        This method is used to find the available environment tasks for a particular split in the dataset.
        """
        if split == "train":
            return train_tasks
        elif split == "test":
            return test_tasks
        raise ValueError(f"Unknown split: {split}")

    @classmethod
    def list_splits(cls) -> list[str]:
        """
        This method is used to list all the splits in the dataset.
        """
        return ["train", "test"]

    def get_prompt(self) -> str:
        """
        This method is used to obtain the prompt that should be used when the agent is starting an episode in the environment.
        """
        return [TextBlock(type="text", text=self.config.problem)]

    @tool
    async def answer(self, params: AnswerParams) -> ToolOutput:
        """
        The answer tool can be used to submit your final answer. Note that this finishes the episode.
        """
        # The docstring above becomes part of the tool description which the language model has access to. You should use it to explain how to use the tool to the agent.

        # Below is mock logic that show the main principles of tools: they take in arguments from the agent, interact with state, and are used to produce a ToolResult
        if params.answer == self.config.solution:
            is_correct = True
            final_text = "Correct!"
        else:
            is_correct = False
            final_text = "Wrong!"

        return ToolOutput(
            blocks=[TextBlock(type="text", text=final_text)],
            reward=1.0 if is_correct else 0.0,
            finished=True
        )

if __name__ == "__main__":
    Server([BasicEnvironment]).run()
